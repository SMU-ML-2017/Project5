{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "matplotlib.rcParams.update({'figure.figsize': (10, 6)})\n",
    "matplotlib.rcParams.update({'font.size': 16})\n",
    "matplotlib.rcParams.update({'axes.labelsize': 20})\n",
    "matplotlib.rcParams.update({'xtick.labelsize': 12})\n",
    "matplotlib.rcParams.update({'ytick.labelsize': 12})\n",
    "matplotlib.rcParams.update({'font.family': 'Helvetica, Arial, sans-serif'})\n",
    "\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning lab 5: evaluation and multi-layer perceptron \n",
    "## Jake Rowland and Paul Herz\n",
    "2017-10-20\n",
    "\n",
    "> **Nota bene:** much of this introductory text that describes the classification task and dataset preparation is replicated from our previous project, which in turn is heavily based upon the logic and processes from our first project, as all three share the same dataset, and we do not wish to produce new and redundant boilerplate to describe that same dataset.\n",
    "\n",
    "## 1. Introduction\n",
    "\n",
    "*Partially reproduced from Lab 4, with additional notes on problems discovered since and our approach to preserving consistency*\n",
    "\n",
    "Here we return to the dataset of our initial project, [Exploring Table Data](https://github.com/SMU-ML-2017/Project1/blob/master/ML%20Lab%201.ipynb), wherein we graphically analyzed the trends in the [IMDB Top 5000 Movie Dataset](https://www.kaggle.com/deepmatrix/imdb-5000-movie-dataset). One aspect of our analysis in that project centered around dividing the set of films into three groups: **poor**, **average**, and **good**. This was a simplification of IMDB's 10-point rating system, and grouped films into asymmetric quantiles. It allowed us to cut arbitrary lines in the large group of films to illustrate trends among the upper percentile films versus the rest. \n",
    "\n",
    "In our fourth project, we employed several classification techniques to predict how the properties of a movie's production applied to its classification under these three labels. We came to the realization, very late in the project, that the performance of our classifier was much poorer than expected when operating upon this dataset and this classification task. In our post-mortem review, we came to the conclusion that this was not the fault of our homespun logistic regression classifier, but an inherent issue in how we handled the dataset. We make no claim that there is a fundamental issue with the source dataset, but the method with which we applied abritrary class labels onto the dataset was **fundamentally flawed**. Instead of separating well-defined clusters of films based on any number of properties, we delineated films, as described above, with percentiles on a normal distribution. Not only did this lead to significant class imbalance, but almost identical data points were separated along arbitrary lines.\n",
    "\n",
    "We did **not** attempt to change this labeling process in our fourth project for the sake of consistency, even though we already somewhat understood from visualizations in our first project that this method was flawed and would negatively effect performance of any classifiers. For the same reason, **we will not modify our flawed labelling approach here**, if only so that classification methods used here can be fairly compared with methods in our fourth project. Changing our arbitrary labelling approach, or even our dataset in this project would better serve our metrics but threaten the usefulness of this report in the context of our other reports.\n",
    "\n",
    "Here, we will use this classification task on the films dataset to illustrate the performance and functionality of a homespun multilayer perceptron implementation, as well as to outline our processes for cross-validation and evaluation.\n",
    "\n",
    "### 1.1 Background\n",
    "\n",
    "*Wholly reproduced from Lab 4*\n",
    "\n",
    "This dataset represents data compiled entirely by IMDB, whose primary purpose is as a compendium of films. In the previous use of this dataset, we mostly considered how this dataset serves as a representation of trends in American and international cinema. This time, we want to consider the films more in the context of IMDB as an application, and the trends of American film consumers.\n",
    "\n",
    "### 1.2 Business Case\n",
    "\n",
    "*Wholly reproduced from Lab 4*\n",
    "\n",
    "Using the same arbitrary classifications of **poor**, **average**, and **good**, whose definitions depend on the quantile groupings of IMDB out-of-10 scores, we want to use film data (less the scores) to predict a film's classification into one of these groups. We believe that such a feature will be useful to IMDB, which is likely to receive a sizeable portion of traffic from visitors looking up brand-new films. However, brand-new films do not have sufficient reviews for IMDB to formulate their composite out-of-ten score, and must display a placeholder until there is consensus among a statistically significant number of film critics. Instead of leaving users dissatisfied when they cannot quickly determine whether they should see the film, or how it is performing, IMDB can classify the movie as \"probably bad,\" \"probably average,\" or \"probably good.\" This is not as a replacement to critic composites, but to fill in the blank before reviews come in. \n",
    "\n",
    "This capability, to preemptively label new material based on relevant input data like directors, budgets, etc. is of great value to IMDB, and although there is a definite threshold of performance required for meaningful utility of the prediction task, there is no risk presented to IMDB. In the worst-case situation, IMDB provides a preliminary rating that is not quite in line with the forthcoming critics' reviews. What would befall IMDB is akin to what would befall the publisher of a critic whose review is an outlier—absolutely nothing. In the best-case situation, this preemptive rating adds value to the IMDB platform as it advises moviegoers on the probable quality of brand-new films, which will increase traffic and therefore advertisement revenue.\n",
    "\n",
    "### 1.3 Serviceability\n",
    "\n",
    "*Wholly reproduced from Lab 4*\n",
    "\n",
    "As it was mentioned, this task and its implementation as a value-adding tool in the IMDB interface presents virtually no risk to IMDB, even if it were to perform poorly. However, there is a definite point in the range of possible performance at which the product becomes *useful*. We believe that our model must be 80% accurate to gain public trust when our preemptive ratings are referred to — a 1 in 5 chance of predicting a movie to be poor/average/good when it is not. This number may seem arbitrary, but it is our best approximation of an error rate that an end user would be willing to tolerate.\n",
    "\n",
    "## 2. The dataset: preprocessing and review\n",
    "\n",
    "*Partially reproduced from Lab 4*\n",
    "\n",
    "### 2.1 Dataset preparation\n",
    "\n",
    "Below, we load the dataset and reorder columns in a more reasonable fashion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = pd.read_csv('movie_metadata.csv')\n",
    "\n",
    "# Reorder the DataFrame to a more intelligent fashion\n",
    "m = m[[\n",
    "    'movie_title','title_year',\n",
    "    'genres', 'plot_keywords', 'duration',\n",
    "    'budget', 'gross',\n",
    "    'language', 'country', 'content_rating',\n",
    "    'color', 'aspect_ratio',\n",
    "    'facenumber_in_poster',\n",
    "    'director_name',\n",
    "    'actor_1_name', 'actor_2_name', 'actor_3_name',\n",
    "    'movie_facebook_likes', 'director_facebook_likes', 'actor_1_facebook_likes', 'actor_2_facebook_likes',\n",
    "    'actor_3_facebook_likes', 'cast_total_facebook_likes',\n",
    "    'movie_imdb_link', 'num_user_for_reviews', 'num_critic_for_reviews', 'num_voted_users',\n",
    "    'imdb_score',\n",
    "]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Additionally, we cast integral data columns out of the default float type, to ensure the data is best represented by the right type. We follow by removing duplicates, and then copying the dataset before further destructive preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie_title</th>\n",
       "      <th>title_year</th>\n",
       "      <th>genres</th>\n",
       "      <th>plot_keywords</th>\n",
       "      <th>duration</th>\n",
       "      <th>budget</th>\n",
       "      <th>gross</th>\n",
       "      <th>language</th>\n",
       "      <th>country</th>\n",
       "      <th>content_rating</th>\n",
       "      <th>...</th>\n",
       "      <th>director_facebook_likes</th>\n",
       "      <th>actor_1_facebook_likes</th>\n",
       "      <th>actor_2_facebook_likes</th>\n",
       "      <th>actor_3_facebook_likes</th>\n",
       "      <th>cast_total_facebook_likes</th>\n",
       "      <th>movie_imdb_link</th>\n",
       "      <th>num_user_for_reviews</th>\n",
       "      <th>num_critic_for_reviews</th>\n",
       "      <th>num_voted_users</th>\n",
       "      <th>imdb_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Avatar</td>\n",
       "      <td>2009.0</td>\n",
       "      <td>Action|Adventure|Fantasy|Sci-Fi</td>\n",
       "      <td>avatar|future|marine|native|paraplegic</td>\n",
       "      <td>178.0</td>\n",
       "      <td>237000000.0</td>\n",
       "      <td>760505847.0</td>\n",
       "      <td>English</td>\n",
       "      <td>USA</td>\n",
       "      <td>PG-13</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>936.0</td>\n",
       "      <td>855.0</td>\n",
       "      <td>4834</td>\n",
       "      <td>http://www.imdb.com/title/tt0499549/?ref_=fn_t...</td>\n",
       "      <td>3054.0</td>\n",
       "      <td>723.0</td>\n",
       "      <td>886204</td>\n",
       "      <td>7.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Pirates of the Caribbean: At World's End</td>\n",
       "      <td>2007.0</td>\n",
       "      <td>Action|Adventure|Fantasy</td>\n",
       "      <td>goddess|marriage ceremony|marriage proposal|pi...</td>\n",
       "      <td>169.0</td>\n",
       "      <td>300000000.0</td>\n",
       "      <td>309404152.0</td>\n",
       "      <td>English</td>\n",
       "      <td>USA</td>\n",
       "      <td>PG-13</td>\n",
       "      <td>...</td>\n",
       "      <td>563.0</td>\n",
       "      <td>40000.0</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>48350</td>\n",
       "      <td>http://www.imdb.com/title/tt0449088/?ref_=fn_t...</td>\n",
       "      <td>1238.0</td>\n",
       "      <td>302.0</td>\n",
       "      <td>471220</td>\n",
       "      <td>7.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Spectre</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>Action|Adventure|Thriller</td>\n",
       "      <td>bomb|espionage|sequel|spy|terrorist</td>\n",
       "      <td>148.0</td>\n",
       "      <td>245000000.0</td>\n",
       "      <td>200074175.0</td>\n",
       "      <td>English</td>\n",
       "      <td>UK</td>\n",
       "      <td>PG-13</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11000.0</td>\n",
       "      <td>393.0</td>\n",
       "      <td>161.0</td>\n",
       "      <td>11700</td>\n",
       "      <td>http://www.imdb.com/title/tt2379713/?ref_=fn_t...</td>\n",
       "      <td>994.0</td>\n",
       "      <td>602.0</td>\n",
       "      <td>275868</td>\n",
       "      <td>6.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The Dark Knight Rises</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>Action|Thriller</td>\n",
       "      <td>deception|imprisonment|lawlessness|police offi...</td>\n",
       "      <td>164.0</td>\n",
       "      <td>250000000.0</td>\n",
       "      <td>448130642.0</td>\n",
       "      <td>English</td>\n",
       "      <td>USA</td>\n",
       "      <td>PG-13</td>\n",
       "      <td>...</td>\n",
       "      <td>22000.0</td>\n",
       "      <td>27000.0</td>\n",
       "      <td>23000.0</td>\n",
       "      <td>23000.0</td>\n",
       "      <td>106759</td>\n",
       "      <td>http://www.imdb.com/title/tt1345836/?ref_=fn_t...</td>\n",
       "      <td>2701.0</td>\n",
       "      <td>813.0</td>\n",
       "      <td>1144337</td>\n",
       "      <td>8.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Star Wars: Episode VII - The Force Awakens    ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Documentary</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>131.0</td>\n",
       "      <td>131.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>143</td>\n",
       "      <td>http://www.imdb.com/title/tt5289954/?ref_=fn_t...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "      <td>7.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         movie_title  title_year  \\\n",
       "0                                            Avatar       2009.0   \n",
       "1          Pirates of the Caribbean: At World's End       2007.0   \n",
       "2                                           Spectre       2015.0   \n",
       "3                             The Dark Knight Rises       2012.0   \n",
       "4  Star Wars: Episode VII - The Force Awakens    ...         NaN   \n",
       "\n",
       "                            genres  \\\n",
       "0  Action|Adventure|Fantasy|Sci-Fi   \n",
       "1         Action|Adventure|Fantasy   \n",
       "2        Action|Adventure|Thriller   \n",
       "3                  Action|Thriller   \n",
       "4                      Documentary   \n",
       "\n",
       "                                       plot_keywords  duration       budget  \\\n",
       "0             avatar|future|marine|native|paraplegic     178.0  237000000.0   \n",
       "1  goddess|marriage ceremony|marriage proposal|pi...     169.0  300000000.0   \n",
       "2                bomb|espionage|sequel|spy|terrorist     148.0  245000000.0   \n",
       "3  deception|imprisonment|lawlessness|police offi...     164.0  250000000.0   \n",
       "4                                                NaN       NaN          NaN   \n",
       "\n",
       "         gross language country content_rating     ...      \\\n",
       "0  760505847.0  English     USA          PG-13     ...       \n",
       "1  309404152.0  English     USA          PG-13     ...       \n",
       "2  200074175.0  English      UK          PG-13     ...       \n",
       "3  448130642.0  English     USA          PG-13     ...       \n",
       "4          NaN      NaN     NaN            NaN     ...       \n",
       "\n",
       "  director_facebook_likes  actor_1_facebook_likes  actor_2_facebook_likes  \\\n",
       "0                     0.0                  1000.0                   936.0   \n",
       "1                   563.0                 40000.0                  5000.0   \n",
       "2                     0.0                 11000.0                   393.0   \n",
       "3                 22000.0                 27000.0                 23000.0   \n",
       "4                   131.0                   131.0                    12.0   \n",
       "\n",
       "  actor_3_facebook_likes cast_total_facebook_likes  \\\n",
       "0                  855.0                      4834   \n",
       "1                 1000.0                     48350   \n",
       "2                  161.0                     11700   \n",
       "3                23000.0                    106759   \n",
       "4                    NaN                       143   \n",
       "\n",
       "                                     movie_imdb_link num_user_for_reviews  \\\n",
       "0  http://www.imdb.com/title/tt0499549/?ref_=fn_t...               3054.0   \n",
       "1  http://www.imdb.com/title/tt0449088/?ref_=fn_t...               1238.0   \n",
       "2  http://www.imdb.com/title/tt2379713/?ref_=fn_t...                994.0   \n",
       "3  http://www.imdb.com/title/tt1345836/?ref_=fn_t...               2701.0   \n",
       "4  http://www.imdb.com/title/tt5289954/?ref_=fn_t...                  NaN   \n",
       "\n",
       "   num_critic_for_reviews  num_voted_users  imdb_score  \n",
       "0                   723.0           886204         7.9  \n",
       "1                   302.0           471220         7.1  \n",
       "2                   602.0           275868         6.8  \n",
       "3                   813.0          1144337         8.5  \n",
       "4                     NaN                8         7.1  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reduce the number of float64 data types for columns that do not need a float64 data type\n",
    "for col in ['title_year','facenumber_in_poster',\n",
    "'movie_facebook_likes','actor_1_facebook_likes','actor_2_facebook_likes',\n",
    "'actor_3_facebook_likes','cast_total_facebook_likes','num_user_for_reviews',\n",
    "'num_critic_for_reviews','num_voted_users']:\n",
    "    m[col] = pd.to_numeric(m[col],downcast='integer')\n",
    "  \n",
    "# Remove all duplicate entries\n",
    "m.drop_duplicates(inplace=True)\n",
    "\n",
    "# Create a copy to perserve the original DataFrame\n",
    "m_original=m.copy()\n",
    "m.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Data quality\n",
    "\n",
    "As described in our prior report on this dataset, it presents numerous data consistency and quality challenges to be overcome before it can be useful for analysis. One problem that we inspected and demonstrated in the prior report was as follows: some films were massive outliers on the budget and gross scale, one film in particular making an absurd amount of money: Studio Ghibli's *Princess Mononoke*. We posited that this may have been because it was in Japanese Yen (JPY), a much smaller unit of currency than the US Dollar (USD), and a quick verification of the IMDB website confirmed our suspicions. Unfortunately, this dataset stores all financial quantities as bare numbers, and there is no reasonable means of guessing which currency is being referred to. Our best solution to avoid this massive inaccuracy was to remove all non-US films, working off the reasonable assumption that all US films would have financial figures reported in USD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove all films except those from the United States\n",
    "m = m[m['country'] == 'USA']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another inconsistency arose when we realized that, unfortunately, a number of television series and other non-cinematic formats were being included in this list. This may be an oversight of those preparing this dataset from the IMDB corpus, as the dataset is supposedly \"5000 Movies,\" and nothing more. One challenge presented by the mixture of media formats is the inability to compare homogeneous instances—for example, if we were to use running time as a metric in our prediction task, TV series would represent a large outlier, as IMDB lists the series' *full running times* of all episodes. In fact, this was how the issue of non-cinematic instances being present in the dataset was initially uncovered in preliminary analysis during our prior report. In order to filter such content out, we've found the most reliable means to be removing those items which do not feature a standard, common, and mainstream content explicitness rating: G, PG, PG-13, or R."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove items with non-American or non-film rating systems\n",
    "m = m[m['content_rating'].isin(['R','PG-13','PG','G'])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To address the number of films containing null fields, we use common-sense and statistics to handle inconsistent instances. In the case of most fields, we remove instances with missing columns. The reasoning behind this is that the fields we remove for represent fairly common data, and a film missing this data may be very esoteric or poorly documented in IMDB to miss it. We believe Facebook likes are very likely to correlate with ratings in the case of some larger modern movies, so we strip those films which lack Facebook data for film Fan pages and actor individual profiles.\n",
    "\n",
    "Other fields can be imputed: we assume a lack of a review count means there are zero reviews, and we use the mean of all faces in film posters to replace null values for `facenumber_in_poster`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove rows where the value is null\n",
    "for col in ['title_year', 'language','country','content_rating',\n",
    "'aspect_ratio','duration', 'color','gross','budget','movie_facebook_likes',\n",
    "'actor_1_facebook_likes','actor_2_facebook_likes','actor_3_facebook_likes',\n",
    "'cast_total_facebook_likes']:\n",
    "    try:\n",
    "        m = m[pd.notnull(m[col])]\n",
    "    except KeyError:\n",
    "        pass\n",
    "    \n",
    "# Assume null review counts are 0\n",
    "for col in ['num_user_for_reviews','num_critic_for_reviews']:\n",
    "    m[col].fillna(value=0,inplace=True)\n",
    "    \n",
    "# Assume missing face counts are the mean\n",
    "avgFace = round(m['facenumber_in_poster'].mean())\n",
    "m['facenumber_in_poster'].fillna(value=avgFace, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Arbitrary class generation: the three rating classes\n",
    "\n",
    "Below, we generate the arbitrary partitions of the dataset along the IMDB out-of-10 scores. This will simplify the classification process beyond the theoretically 100 possible scores (0.0-10.0 in increments of 1) or the 10 possible scores if we were to round or truncate to whole numbers. First we determine the boundaries along the range of possible scores at which we will partition the dataset (`poor_avg` and `avg_good`). These are based off of the 50th percentile point and the 90th percentile point, respectively.\n",
    "\n",
    "**Note:** this is the aforementioned arbitrary labelling process that caused many of the issues in the previous project. Refer to the introduction for a thorough and hopefully sufficient explanation of why we have decided to not modify this flawed approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'imdb_score'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m~/.local/share/virtualenvs/Project5-VSMTCPEv/lib/python3.6/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2441\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2442\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2443\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc (pandas/_libs/index.c:5280)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc (pandas/_libs/index.c:5126)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item (pandas/_libs/hashtable.c:20523)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item (pandas/_libs/hashtable.c:20477)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'imdb_score'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-64-99f0aa2ef951>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Categorize the IMDB score into three classes:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# [0%-49%] is Poor, [50%-89%] is Average, [90%-100%] is Good.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mpoor_avg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'imdb_score'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquantile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mavg_good\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'imdb_score'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquantile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m.9\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/Project5-VSMTCPEv/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1962\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1963\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1964\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1965\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1966\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_getitem_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/Project5-VSMTCPEv/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_getitem_column\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1969\u001b[0m         \u001b[0;31m# get column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1970\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_unique\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1971\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_item_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1972\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1973\u001b[0m         \u001b[0;31m# duplicate columns & possible reduce dimensionality\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/Project5-VSMTCPEv/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_get_item_cache\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m   1643\u001b[0m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1644\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mres\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1645\u001b[0;31m             \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1646\u001b[0m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_box_item_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1647\u001b[0m             \u001b[0mcache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/Project5-VSMTCPEv/lib/python3.6/site-packages/pandas/core/internals.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, item, fastpath)\u001b[0m\n\u001b[1;32m   3588\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3589\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misnull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3590\u001b[0;31m                 \u001b[0mloc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3591\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3592\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0misnull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/Project5-VSMTCPEv/lib/python3.6/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2442\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2443\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2444\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2445\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2446\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc (pandas/_libs/index.c:5280)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc (pandas/_libs/index.c:5126)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item (pandas/_libs/hashtable.c:20523)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item (pandas/_libs/hashtable.c:20477)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'imdb_score'"
     ]
    }
   ],
   "source": [
    "# Categorize the IMDB score into three classes:\n",
    "# [0%-49%] is Poor, [50%-89%] is Average, [90%-100%] is Good.\n",
    "poor_avg = m['imdb_score'].quantile(.5)\n",
    "avg_good = m['imdb_score'].quantile(.9)\n",
    "\n",
    "m['rating_category'] = pd.cut(\n",
    "    m.imdb_score,[0,poor_avg,avg_good,10],\n",
    "    labels=['poor','average','good']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Removing irrelevant fields\n",
    "\n",
    "We will follow by removing columns that are unreasonable to categorize (e.g. names and multi-value genres), and those irrelevant to classification (IMDB page URLs). Now that we have sorted films by IMDB score into rating classes, we also remove the IMDB score field. Country and language are removed as we have limited films to the United States, and the list of possible languages is too long."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in ['movie_title','plot_keywords','actor_1_name','actor_2_name','actor_3_name',\n",
    "'movie_imdb_link','genres', 'director_name','imdb_score','aspect_ratio','country','language']:\n",
    "    m.drop(c, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We make `content_rating` and `color` categorical, as their possible values are small, and they may correlate meaningfully to certain rating classes. This is a preliminary step before one-hot encoding necessary for classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert categorical values to category type\n",
    "for col in ['content_rating','color']:\n",
    "    m[col] = m[col].astype('category')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Modifying the dataset for classification compatibility\n",
    "\n",
    "What has been done to the dataset so far mostly resembles the preprocessing we performed in our prior report touching on this same dataset. What follows represents the additional processing necessary for the classification we will be performing.\n",
    "\n",
    "First, categorical types such as `color` and `content_rating` are not at all useful to a classifier. We will convert these non-ordinal types into one-hot columns, due to the limited number of categories in each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace color and content_rating with dummies\n",
    "m = pd.get_dummies(m, columns=['color','content_rating'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since rating category (poor, average, good) is both (1) our target for classification in a one-versus-rest format, and (2) an ordinal value (poor < average < good), we convert the rating category field not to a one-hot set, but an enumerated integer code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1560\n",
       "1    1086\n",
       "2     276\n",
       "Name: rating_category, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if m.rating_category.dtype != np.dtype('int8'):\n",
    "    m.rating_category = m.rating_category.cat.codes\n",
    "m.rating_category.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Final format after preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 2922 entries, 0 to 5042\n",
      "Data columns (total 21 columns):\n",
      "title_year                   2922 non-null float64\n",
      "duration                     2922 non-null float64\n",
      "budget                       2922 non-null float64\n",
      "gross                        2922 non-null float64\n",
      "facenumber_in_poster         2922 non-null float64\n",
      "movie_facebook_likes         2922 non-null int32\n",
      "director_facebook_likes      2922 non-null float64\n",
      "actor_1_facebook_likes       2922 non-null float64\n",
      "actor_2_facebook_likes       2922 non-null float64\n",
      "actor_3_facebook_likes       2922 non-null float64\n",
      "cast_total_facebook_likes    2922 non-null int32\n",
      "num_user_for_reviews         2922 non-null float64\n",
      "num_critic_for_reviews       2922 non-null float64\n",
      "num_voted_users              2922 non-null int32\n",
      "rating_category              2922 non-null int8\n",
      "color_ Black and White       2922 non-null uint8\n",
      "color_Color                  2922 non-null uint8\n",
      "content_rating_G             2922 non-null uint8\n",
      "content_rating_PG            2922 non-null uint8\n",
      "content_rating_PG-13         2922 non-null uint8\n",
      "content_rating_R             2922 non-null uint8\n",
      "dtypes: float64(11), int32(3), int8(1), uint8(6)\n",
      "memory usage: 328.2 KB\n"
     ]
    }
   ],
   "source": [
    "m.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final format of the dataset has changed significantly from the original, in a way we believe improves the quality and consistency of the data, as well as best preparing it for classification in the following code. All of the initial columns are unchanged other than some (attempts at) data casting to integral formats.\n",
    "\n",
    "`title_year` is the release year of the film, `duration` is the number of minutes the film screens for, `budget` and `gross` are financial figures in USD, `facenumber_in_poster` is the number of (human) faces on the advertising poster for the film, `..._facebook_likes` are figures for the Facebook popularity of the film and related figures, `..._for_reviews` etc. are data for the population size of both professional and lay reviewers.\n",
    "\n",
    "The columns that have been added are as follows:\n",
    "\n",
    "- `rating_category`: ordinal representation of the arbitrary classification of `poor`, `average`, `good`, classifications based on quantile grouping of IMDB out-of-ten scores, which have been stripped from the dataset.\n",
    "- `color_ Black and White` and `color_Color`: one-hot encoding fields for the categorical type `color` (removed here), representing the type of photographic technology used to record the film, and whether it depicted color or not.\n",
    "- `content_rating_G`, `...PG`, `...PG-13`, `...R`: one-hot encoding fields for the categorical type `content_rating` (removed here), not to be confused with `rating_category`. This is the MPAA explicit content rating for the film."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preparation of the training and testing sets\n",
    "\n",
    "Now we prepare the material which will be used directly in our classification task. Here, `X` represents all instances, less the target variable `rating_category`, whereas `y` is a vector of the target variable for all instances.\n",
    "\n",
    "In the previous project, we simply performed a train-test split upon the dataset. Whereas we intended to train with 80% and test with 20%, we erroneously did the opposite. Regardless, in this report, we endeavour to use a more rigorous methodology for dividing our data. This decision, as well as evaluation criteria, is deferred to the next section, as it represents significant discussion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=m.drop('rating_category', axis=1, inplace=False)\n",
    "y=np.ravel(m['rating_category'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Evaluation, training, and testing\n",
    "\n",
    "### 3.1 Evaluation criteria\n",
    "\n",
    "How best to evaluate the performance of our algorithm was a difficult matter for us. Wary of the caveats vis-à-vis accuracy as a scoring function, we looked through our other options. \n",
    "\n",
    "Bear in mind, once more, that our task involves labelling films as either **poor**, **average**, or **good**. These are somewhat \"fuzzy\" labels: there is not an immediate, quantifiable distinction between one label and the other, as we have divided the dataset based on subjective user-sourced scoring rather than some other property. It is entirely unlike a more  stereotypical classification problem, e.g. in the domains of medicine (seropositive/seronegative, malignant/benign, etc.) or vision (handwritten digits). Not only are the delineations imprecise by definition, but misclassification is not an objective failure (unlike the above tasks). \n",
    "\n",
    "As such, when considering scorers, we rejected **recall**, which puts greater significance upon false negatives than we desired. We do not believe that missing a certain number of films in the poor/average/good classes is of the utmost importance, partially because of the imprecise nature of these classes, but also because of the real-world implications. Providing an end-user with the wrong arbitrary classification in our business case is not serious, as we have mentioned that our classifications should be placeholders, and probably bear some kind of warning or visual cue that they do not represent forthcoming review data.\n",
    "\n",
    "Not simply as a fallback, we truly believe that **accuracy** best fits the priorities and realities of this classification task, as we want our scores to represent how closely our algorithm approximates human critics, above anything else. IMDB scores represent averaged consensus, but no specific critic represents the average—*not everyone agrees on the merit of films*, and to punitively score missed labels for each class would be to misunderstand the diversity of human opinion. The subjective nature of this classification task enables us to use accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import make_scorer, accuracy_score\n",
    "scorer = make_scorer(accuracy_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Training-testing split\n",
    "With regard to the preparation of training and testing sets, we endeavor to move ahead from the simple percentage-split employed in our previous report. We have analyzed our options and discussed how they will impact and improve our process. Thankfully, our dataset does not involve a time-series of data. It does represent years of release, but the chronology of films does not directly affect our approach here. \n",
    "\n",
    "We initially looked at **10-fold cross validation** as a method to add rigor to our evaluation process, but we were concerned about how the distribution of our classes would be represented in the specific resultant folds. We believe that the stratified variant will lend us more stability to the cross validation procedure, and make eventual evaluation data from this CV process more meaningful.\n",
    "\n",
    "In real-world deployment of this algorithm, we assume that the distribution of new films along our arbitrary classifications of **poor**, **average**, and **good** would closely resemble the distribution observed in this source dataset from IMDB, barring some significant change to the viewing habits and industrial practices of the film and entertainment sector. As such, by using **Stratified 10-fold cross validation**, we are ensuring that our model is consistently trained with a training set that represents the distribution of labels from our source set, i.e. \"real-world data.\" \n",
    "\n",
    "We believe our model would be updated at a low enough frequency (monthly, quarterly, yearly) for a meaningful and statistically significant number of new releases to accumulate and be used as training data with which to keep the model current. Given that we expect these new datasets to be large enough to not be aberrant (\"smooth\"), we believe the distribution of labels will be consistent in each new dataset with what has been seen before. Thus, the stratified approach very closely mirrors our expectation for real-world usage of this algorithm: continual, similarly-sized update training sets with similar class balances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "cross_validation = StratifiedKFold(n_splits=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Modeling\n",
    "\n",
    "### 4.1 Our perceptron implementation\n",
    "\n",
    "We began with the official lecture implementation of a two-layer perceptron, specifically a combination of the base class, the TwoLayer implementation, with the addition of vectorized math and minibatching variants. \n",
    "\n",
    "We sought to generalize its support for a single hidden layer of an arbitrary size to an arbitrary number of hidden layers of arbitrary size. This began at a very superficial level, by replacing the `n_hidden: int` initializing parameter (representing the number of units in the one hidden layer) with the more flexible `hidden_layer_sizes: list`. We could have maintained the original name, but that would have been confusing when contrasting with the original behavior of the parameter, and would have made the refactoring process somewhat more difficult.\n",
    "\n",
    "We added the ability for user-defined activation function and cost function, with options `'sigmoid'` and `'linear'`, `'least_squares'` and `'cross_entropy'`, respectively. \n",
    "\n",
    "In most cases, we replaced references to `A1,A2,A3,W1,W2,Z1,Z2` in parameter lists and calculations with lists such as `A`, `weights`, and `Z`. The primary difference, as a result, is that all of these lists are zero-indexed, and therefore `weights[0]` represents the same set of weights as `W1` in the previous code. An added benefit of using lists, other than the ability to generalize beyond a fixed number of variables, is the ability to predictably iterate both forward and backward over these data structures.\n",
    "\n",
    "The process of translating much of the math in the feed-forward and backpropagation steps of the perceptron was arduous. We believe this process was made especially difficult and time-consuming due to the embedding of bias directly into matrices. Discussing this with Dr. Larson, we were informed of the two camps of bias representation: \n",
    "\n",
    "- \"Outties,\" those who separate the bias out, as it is separate in meaning from the data in the matrices in which it is typically embedded, (facilitating programming but slowing down math) and\n",
    "- \"Innies,\" those who embed the bias into related matrices, to facilitate math operations.\n",
    "\n",
    "(nomenclature entirely ours.)\n",
    "\n",
    "In order to avoid rewriting much more of the code and potential issues with forgetting bias terms, we decided to continue along with debugging a large number of failing matrix operations until we had appropriately considered removing the bias term everywhere necessary, as well as dealing with matrix size mismatches caused by a lack of special cases for handling the first/last of the layers.\n",
    "\n",
    "Upon resolving this category of issues with our generalization of the two-layer perceptron, we revealed a more concerning and difficult issue: numbers in our activation matrices were simply replaced by `nan`—a problem that represented a fundamental flaw in our logic. Eventually, through testing and diagnostics, as well as the use of memory inspection and breakpoints, we determined that:\n",
    "\n",
    "1. This issue only arose when the `activation_function` was `'linear'`, and\n",
    "2. This issue was the result of our activation matrices' values rapidly outsizing the limits of 64-bit floating point numbers.\n",
    "\n",
    "We determined that by modifying the implementation of our linear activation function to always normalize its output to within [-1.0,1.0], there would never occur such a runaway effect in the feed-forward process. We confirmed this fix to be successful in consequent testing. \n",
    "\n",
    "For purposes of clarity, we removed the `_sigmoid` method and instead implemented a new `_activation_function` method that would dynamically check the `self.activation_function` property and calculate output accordingly. Similarly, we rewrote the `_cost` method to perform a similar dynamic check. This lends clarity to our customizable implementation, but perhaps is not the most optimized approach for methods being called very frequently during batch/vectorized processes, as generally any conditional statements expose highly iterative methods to branch prediction issues of performance. However, we do not believe computational efficiency is within the scope of this report—we do not want to prematurely optimize an implementation which is still being evaluated for actual predictive performance.\n",
    "\n",
    "We also made our implementation compliant with the Scikit interfaces `BaseEstimator` and `ClassifierMixin`, in order to enable our model to be fed through certain cross-validation and grid search methods, which expect these interfaces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from scipy.special import expit\n",
    "\n",
    "class MultiLayerPerceptron(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(\n",
    "        self, alpha=0.0, decrease_const=0.0, shuffle=True, minibatches=1,\n",
    "        hidden_layer_sizes=[10,10,10], l2_C=0.0, epochs=500, eta=0.001, random_state=None,\n",
    "        activation_function='sigmoid', cost_function='least_squares'\n",
    "    ):\n",
    "        # need to add to the original initializer \n",
    "        self.alpha = alpha\n",
    "        self.decrease_const = decrease_const\n",
    "        self.shuffle = shuffle\n",
    "        self.minibatches = minibatches\n",
    "\n",
    "        np.random.seed(random_state)\n",
    "        self.hidden_layer_sizes = hidden_layer_sizes\n",
    "        self.l2_C = l2_C\n",
    "        self.epochs = epochs\n",
    "        self.eta = eta\n",
    "        self.activation_function = activation_function\n",
    "        self.cost_function = cost_function\n",
    "    \n",
    "    @staticmethod\n",
    "    def _encode_labels(y):\n",
    "        \"\"\"Encode labels into one-hot representation\"\"\"\n",
    "        onehot = pd.get_dummies(y).values.T\n",
    "        return onehot\n",
    "\n",
    "    def _initialize_weights(self):\n",
    "        \"\"\"Initialize weights with small random numbers.\"\"\"\n",
    "        weights = []\n",
    "\n",
    "        sizes = [self.n_features_, *self.hidden_layer_sizes, self.n_output_]\n",
    "        pairs = zip(sizes[0::1], sizes[1::1])\n",
    "\n",
    "        for previous_size, next_size in pairs:\n",
    "            weight_size = (previous_size + 1) * next_size\n",
    "            weight = np.random.uniform(-1.0, 1.0, size=weight_size)\n",
    "            weight = weight.reshape(next_size, previous_size + 1)\n",
    "            weights.append(weight)\n",
    "        \n",
    "        return weights\n",
    "    \n",
    "    def _activation_function(self, z):\n",
    "        new_z = np.copy(z)\n",
    "        if self.activation_function == 'linear':\n",
    "            # normalize within -1.0...1.0\n",
    "            new_z /= np.max(np.abs(new_z),axis=0)\n",
    "            return new_z\n",
    "        elif self.activation_function == 'sigmoid':\n",
    "            return expit(new_z)\n",
    "        else:\n",
    "            raise ValueError(\n",
    "                'The activation_function parameter was an unexpected value:',\n",
    "                f'\"{self.activation_function}\" (should be \"linear\" or \"sigmoid\")'\n",
    "            )\n",
    "    \n",
    "    @staticmethod\n",
    "    def _add_bias_unit(X, how='column'):\n",
    "        \"\"\"Add bias unit (column or row of 1s) to array at index 0\"\"\"\n",
    "        if how == 'column':\n",
    "            ones = np.ones((X.shape[0], 1))\n",
    "            X_new = np.hstack((ones, X))\n",
    "        elif how == 'row':\n",
    "            ones = np.ones((1, X.shape[1]))\n",
    "            X_new = np.vstack((ones, X))\n",
    "        return X_new\n",
    "    \n",
    "    @staticmethod\n",
    "    def _without_bias(X, how='column'):\n",
    "        if how == 'column':\n",
    "            return X[:,1:]\n",
    "        elif how == 'row':\n",
    "            return X[1:,:]\n",
    "    \n",
    "    @staticmethod\n",
    "    def _L2_reg(lambda_, weights):\n",
    "        \"\"\"Compute L2-regularization cost\"\"\"\n",
    "        # only compute for non-bias terms\n",
    "        # TODO: vectorize\n",
    "        result = 0.0\n",
    "        for weight in weights:\n",
    "            result += np.mean(weight[:, 1:] ** 2)\n",
    "        return (lambda_/2.0) * np.sqrt(result)\n",
    "    \n",
    "    def _cost(self,An,Y_enc,weights):\n",
    "        '''Get the objective function value'''\n",
    "        # COST FUNCTION\n",
    "        cost = 0.0\n",
    "        if self.cost_function == 'least_squares':\n",
    "            cost = np.mean((Y_enc-An)**2)\n",
    "        elif self.cost_function == 'cross_entropy':\n",
    "            cost = np.mean(Y_enc * np.log(An) + (1.0 - Y_enc) * np.log(1.0 - An))\n",
    "        else:\n",
    "            raise ValueError(f'Expected cost function names \"least_squares\" or \"cross_entropy\" (\"{self.cost_function}\")')\n",
    "        \n",
    "        # REGULARIZATION\n",
    "        L2_term = self._L2_reg(self.l2_C, weights)\n",
    "        result = cost+L2_term\n",
    "        if np.any(np.isnan(result)):\n",
    "            raise ValueError('NaN value passed into cost function.')\n",
    "        return result\n",
    "    \n",
    "    #def _feedforward(self, X, W1, W2):\n",
    "    def _feedforward(self, X, weights):\n",
    "        \"\"\"Compute feedforward step\n",
    "        -----------\n",
    "        X : Input layer with original features.\n",
    "        weights (size n)\n",
    "        weights[0]: Weight matrix for input layer -> hidden layer.\n",
    "        weights[1...n-2]: Weight matrices for hidden layer -> hidden layer.\n",
    "        weights[n-1]: Weight matrix for hidden layer -> output layer.\n",
    "        ----------\n",
    "        a (size n+1): activations into layer (or output layer)\n",
    "        z (size n): layer inputs \n",
    "        \"\"\"\n",
    "        A = []\n",
    "        Z = []\n",
    "\n",
    "        # input case\n",
    "        # A1\n",
    "        A.append(self._add_bias_unit(X, how='column'))\n",
    "        # Z1\n",
    "        Z.append(weights[0] @ A[0].T)\n",
    "\n",
    "        for i in range(1, len(self.hidden_layer_sizes)+1):\n",
    "            a = self._activation_function(Z[-1])\n",
    "            a = self._add_bias_unit(a, how='row')\n",
    "            A.append(a)\n",
    "\n",
    "            # Z2 = W2 @ A2 and so on (but zero-indexed)\n",
    "            z = weights[i] @ A[i]\n",
    "            Z.append(z)\n",
    "\n",
    "        # output case\n",
    "        an = self._activation_function(Z[-1])\n",
    "        A.append(an)\n",
    "        return A,Z\n",
    "    \n",
    "    def _get_gradient(self, A, Z, Y_enc, weights):\n",
    "        \"\"\" Compute gradient step using backpropagation.\n",
    "        \"\"\"\n",
    "        # the derivative varies if we're using sigmoid or linear activation\n",
    "        derivative = lambda a: 0\n",
    "        if self.activation_function == 'linear':\n",
    "            derivative = lambda a: 1\n",
    "        elif self.activation_function == 'sigmoid':\n",
    "            derivative = lambda a: a*(1-a)\n",
    "\n",
    "        sigmas = [None] * len(Z)\n",
    "        gradients = [None] * len(Z)\n",
    "\n",
    "        # output layer case\n",
    "        s = len(sigmas)-1\n",
    "        \n",
    "        sigmas[s] = -2.0*(Y_enc-A[s+1])*derivative(A[s+1])\n",
    "        gradients[s] = sigmas[s] @ A[s].T\n",
    "        \n",
    "        one_hidden_layer = s == 1\n",
    "\n",
    "        # first hidden layer case\n",
    "        if not one_hidden_layer:\n",
    "            sigmas[s-1] = (weights[s].T @ sigmas[s])*derivative(A[s])\n",
    "            gradients[s-1] = self._without_bias(sigmas[s-1],how='row') @ A[s-1].T\n",
    "\n",
    "        # remaining hidden layer case\n",
    "        for i in reversed(range(1, len(Z)-2)):\n",
    "            try:\n",
    "                sigmas[i] = (weights[i+1].T @ self._without_bias(sigmas[i+1],how='row'))*derivative(A[i+1])\n",
    "                gradients[i] = self._without_bias(sigmas[i],how='row') @ A[i].T\n",
    "            except ValueError:\n",
    "                raise\n",
    "\n",
    "        # input layer case\n",
    "        next_sigma = sigmas[1]\n",
    "        if not one_hidden_layer:\n",
    "            next_sigma = self._without_bias(next_sigma,how='row')\n",
    "        \n",
    "        # sigmas[0] = (weights[1].T @ next_sigma)*A[1]*(1-A[1])\n",
    "        sigmas[0] = (weights[1].T @ next_sigma)*derivative(A[1])\n",
    "        gradients[0] = self._without_bias(sigmas[0],how='row') @ A[0]\n",
    "\n",
    "        # regularize weights that are not bias terms\n",
    "        for i in range(len(gradients)):\n",
    "            try:\n",
    "                gradients[i][:, 1:] += self._without_bias(weights[i], how='column') * self.l2_C\n",
    "            except ValueError:\n",
    "                raise\n",
    "        return gradients\n",
    "    \n",
    "    def predict(self, X):\n",
    "        \"\"\"Predict class labels\"\"\"\n",
    "        A, _ = self._feedforward(X, self.weights)\n",
    "        y_pred = np.argmax(A[-1], axis=0)\n",
    "        return y_pred\n",
    "    \n",
    "    def fit(self, X, y, print_progress=False):\n",
    "        \"\"\" Learn weights from training data.\"\"\"\n",
    "        X_data, y_data = X.copy(), y.copy()\n",
    "        Y_enc = self._encode_labels(y)\n",
    "        \n",
    "        # init weights and setup matrices\n",
    "        self.n_features_ = X_data.shape[1]\n",
    "        self.n_output_ = Y_enc.shape[0]\n",
    "        \n",
    "        self.weights = self._initialize_weights()\n",
    "\n",
    "        self.cost_ = []\n",
    "        for i in range(self.epochs):\n",
    "            if print_progress > 0 and (i+1) % print_progress == 0:\n",
    "                sys.stderr.write(f'\\rEpoch: {i+1}/{self.epochs}')\n",
    "                sys.stderr.flush()\n",
    "\n",
    "            # feedforward all instances\n",
    "            A, Z = self._feedforward(X_data, self.weights)\n",
    "            cost = self._cost(A[-1], Y_enc, self.weights)\n",
    "            self.cost_.append(cost)\n",
    "\n",
    "            # compute gradient via backpropagation\n",
    "            gradients = self._get_gradient(A, Z, Y_enc, self.weights)\n",
    "            for i, gradient in enumerate(gradients):\n",
    "                self.weights[i] -= self.eta * gradient\n",
    "        if print_progress > 0:\n",
    "            print()\n",
    "        return self\n",
    "    \n",
    "    # [CITE] http://algoadventures.com/sklearn-from-the-source-code-up-basics/\n",
    "    # ClassifierMixin implementation\n",
    "    def score(self, X, y, sample_weight=None):\n",
    "        from sklearn.metrics import accuracy_score\n",
    "        return accuracy_score(y, self.predict(X), sample_weight=sample_weight)\n",
    "    # end implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Selection of hyperparameters\n",
    "\n",
    "Thanks to our implementation of scikit's `BaseEstimator` and `ClassifierMixin` interfaces in our perceptron, we are able to take advantage of scikit's inbuilt grid search algorithm. \n",
    "\n",
    "https://stackoverflow.com/a/37163377"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "\n",
    "nn = MultiLayerPerceptron(\n",
    "    hidden_layer_sizes=[20,20], \n",
    "    l2_C=0.1, # tradeoff L2 regularizer\n",
    "    epochs=100, # iterations\n",
    "    eta=0.001,  # learning rate\n",
    "    random_state=1,\n",
    "    alpha=0.001,# momentum calculation\n",
    "    decrease_const=0.0001, # decreasing eta\n",
    "    minibatches=50, # minibatch size\n",
    "    shuffle=True,\n",
    "    activation_function='sigmoid',\n",
    "    cost_function='cross_entropy'\n",
    ")\n",
    "\n",
    "costs = [0.001, 0.01, 0.1, 1, 10, 100]\n",
    "etas  = [0.000001, 0.00001, 0.0001, 0.001, 0.01]\n",
    "\n",
    "param_grid = {\n",
    "    'l2_C': costs,\n",
    "    'eta':  etas\n",
    "}\n",
    "\n",
    "gs = GridSearchCV(nn, param_grid, scoring=scorer, cv=10)\n",
    "gs.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nn = MultiLayerPerceptron(\n",
    "#     hidden_layer_sizes=[50,50,50], \n",
    "#     l2_C=0.01, # tradeoff L2 regularizer\n",
    "#     epochs=600, # iterations\n",
    "#     eta=0.001,  # learning rate\n",
    "#     random_state=1,\n",
    "#     alpha=0.001,# momentum calculation\n",
    "#     decrease_const=0.0001, # decreasing eta\n",
    "#     minibatches=50, # minibatch size\n",
    "#     shuffle=True,\n",
    "#     activation_function='sigmoid',\n",
    "#     cost_function='cross_entropy'\n",
    "# )\n",
    "\n",
    "# nn.fit(X_train, y_train, print_progress=50)\n",
    "# yhat = nn.predict(X_test)\n",
    "\n",
    "# print(f'evaluation metric ({evaluation_metric_name}):',evaluation_metric(y_test,yhat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, ax = plt.subplots()\n",
    "# plt.plot(np.arange(nn.epochs), nn.cost_)\n",
    "# plt.title('asdf')\n",
    "# # plt.ylim(-2.0,0)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation and cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "per_fold_eval_criteria = cross_val_score(\n",
    "    estimator=nn,\n",
    "    X=X,\n",
    "    y=y,\n",
    "    cv=cv,\n",
    "    scoring=scorer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'Score')"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABNcAAAMoCAYAAADsiAZmAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\niHANAAAAAAAAcNH/Az6CLv+elW4bAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10b8abc88>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 404,
       "width": 619
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.bar(range(len(per_fold_eval_criteria)),per_fold_eval_criteria)\n",
    "plt.title('Set scores on evaluation criteria')\n",
    "plt.xlabel('Fold #')\n",
    "plt.ylabel('Score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
